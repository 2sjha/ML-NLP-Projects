{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwWcO4TZYtpd"
      },
      "source": [
        "## Shubham Shekhar Jha (sxj220028)\n",
        "### CS6320 - NLP\n",
        "### HW2 - Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the pickle object to reconstruct the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "import pickle\n",
        "\n",
        "\n",
        "def load_pickle(pickle_name: str) -> Dict[str, int]:\n",
        "    with open(pickle_name, \"rb\") as handle:\n",
        "        pickle_dict = pickle.load(handle)\n",
        "\n",
        "    return pickle_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probability of this line is the multiplication of probabilities of each bigram.\n",
        "Calculate this line probability for each of the three languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "import nltk\n",
        "\n",
        "\n",
        "def get_prob(\n",
        "    langs_unigrams: List[Dict[str, int]], langs_bigrams: List[Dict[str, int]], line: str\n",
        ") -> (float, float, float):\n",
        "    line_tokens = nltk.word_tokenize(line)\n",
        "    line_bigrams = list(nltk.ngrams(line_tokens, 2))\n",
        "\n",
        "    eng_unigrams, eng_bigrams = langs_unigrams[0], langs_bigrams[0]\n",
        "    fr_unigrams, fr_bigrams = langs_unigrams[1], langs_bigrams[1]\n",
        "    it_unigrams, it_bigrams = langs_unigrams[2], langs_bigrams[2]\n",
        "    vocab_size = len(eng_unigrams) + len(fr_unigrams) + len(it_unigrams)\n",
        "\n",
        "    eng_prob = 1\n",
        "    fr_prob = 1\n",
        "    it_prob = 1\n",
        "    for bigram in line_bigrams:\n",
        "        first_word = bigram[0]\n",
        "\n",
        "        eng_bi_count = eng_bigrams[bigram] if bigram in eng_bigrams else 0\n",
        "        fr_bi_count = fr_bigrams[bigram] if bigram in fr_bigrams else 0\n",
        "        it_bi_count = it_bigrams[bigram] if bigram in it_bigrams else 0\n",
        "\n",
        "        eng_fw_count = eng_unigrams[first_word] if first_word in eng_unigrams else 0\n",
        "        fr_fw_count = fr_unigrams[first_word] if first_word in fr_unigrams else 0\n",
        "        it_fw_count = it_unigrams[first_word] if first_word in it_unigrams else 0\n",
        "\n",
        "        eng_prob = eng_prob * ((eng_bi_count + 1) / (eng_fw_count + vocab_size))\n",
        "        fr_prob = fr_prob * ((fr_bi_count + 1) / (fr_fw_count + vocab_size))\n",
        "        it_prob = it_prob * ((it_bi_count + 1) / (it_fw_count + vocab_size))\n",
        "\n",
        "    return (eng_prob, fr_prob, it_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each line in the test file calculate the probability of each language and choose the one with the highest probability, also write the predicted language to an output file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PoAN7FKlc9Ci"
      },
      "outputs": [],
      "source": [
        "eng_unigrams = load_pickle(\"eng_unigrams.pickle\")\n",
        "eng_bigrams = load_pickle(\"eng_bigrams.pickle\")\n",
        "\n",
        "fr_unigrams = load_pickle(\"fr_unigrams.pickle\")\n",
        "fr_bigrams = load_pickle(\"fr_bigrams.pickle\")\n",
        "\n",
        "it_unigrams = load_pickle(\"it_unigrams.pickle\")\n",
        "it_bigrams = load_pickle(\"it_bigrams.pickle\")\n",
        "\n",
        "test_text = \"\"\n",
        "with open(\"LangId.test.txt\") as f:\n",
        "    test_text = f.read()\n",
        "\n",
        "with open(\"HW2_Output.txt\", \"w\") as f:\n",
        "    for line in test_text.splitlines():\n",
        "        eng_prob, fr_prob, it_prob = get_prob(\n",
        "            [eng_unigrams, fr_unigrams, it_unigrams],\n",
        "            [eng_bigrams, fr_bigrams, it_bigrams],\n",
        "            line,\n",
        "        )\n",
        "\n",
        "        if eng_prob >= fr_prob and eng_prob >= it_prob:\n",
        "            f.write(\"English\\n\")\n",
        "        elif fr_prob >= eng_prob and fr_prob >= it_prob:\n",
        "            f.write(\"French\\n\")\n",
        "        elif it_prob >= fr_prob and it_prob >= eng_prob:\n",
        "            f.write(\"Italian\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read lines from output and actual files, then count the correct predictions to measure accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Incorrect prediction at line 24\n",
            "Incorrect prediction at line 44\n",
            "Incorrect prediction at line 92\n",
            "Incorrect prediction at line 187\n",
            "Incorrect prediction at line 191\n",
            "Incorrect prediction at line 247\n",
            "Incorrect prediction at line 277\n",
            "Incorrect prediction at line 279\n",
            "\n",
            "Accuracy: 97.33333333333334\n"
          ]
        }
      ],
      "source": [
        "output = \"\"\n",
        "with open(\"HW2_Output.txt\") as f:\n",
        "    output = f.read()\n",
        "\n",
        "acutal = \"\"\n",
        "with open(\"LangId.sol.txt\") as f:\n",
        "    actual = f.read()\n",
        "\n",
        "out_lines = output.splitlines()\n",
        "actual_lines = actual.splitlines()\n",
        "\n",
        "if len(out_lines) != len(actual_lines):\n",
        "    eprint(\"Length of Output and Actual results dont match\")\n",
        "\n",
        "correct = 0\n",
        "for i in range(len(out_lines)):\n",
        "    out_lang = out_lines[i].strip()\n",
        "\n",
        "    if out_lang in actual_lines[i].strip():\n",
        "        correct += 1\n",
        "    else:\n",
        "        print(\"Incorrect prediction at line\", i + 1)\n",
        "\n",
        "print(\"\\nAccuracy:\", ((correct / len(out_lines)) * 100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
