{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CS6320 - NLP Quiz 3\n",
        "## Shubham Shekhar Jha (sxj220028)"
      ],
      "metadata": {
        "id": "gbDSxX3UTp-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK imports"
      ],
      "metadata": {
        "id": "jBhbjjQNUa1Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLLboWhaTZF9",
        "outputId": "ee5a5b00-918a-463d-c867-7200cb2c7467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List two things you learned about the `tokens()` method or Text objects from looking through the code.\n",
        "  - The Text objects in NLTK are wrapper classes for analysis of any given text. The objects are typically instantiated with the sequence of tokens from a corpus or a document.\n",
        "  - An interesting function in the Text class is the `dispersion_plot` function which draws a plot showing the distribution of words through the text."
      ],
      "metadata": {
        "id": "5lNm8W7rVDBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.book import text1\n",
        "tokens_20 = text1.tokens[:20]\n",
        "print(tokens_20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQsWR9CobnHf",
        "outputId": "c8ae71f6-18ca-4dcf-ff5c-d960fec2999a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sea_c = text1.concordance('sea', lines=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQvXZtnSdJR8",
        "outputId": "809f1c2e-e5ca-4f56-cf4c-3fb066f4bd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 455 matches:\n",
            " shall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soever \n",
            " S PLUTARCH ' S MORALS . \" The Indian Sea breedeth the most and the biggest fis\n",
            "cely had we proceeded two days on the sea , when about sunrise a great many Wha\n",
            "many Whales and other monsters of the sea , appeared . Among the former , one w\n",
            " waves on all sides , and beating the sea before him into a foam .\" -- TOOKE ' \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Look at the count() method in the API. How does this work, and how is it different or the same as Python's count method?\n",
        "   - The count method in the NLTK Text class is essentially the default `count` function from Python. NLTK's `count` function effectively calls the default `count` function on the `tokens` list; thus they produce the same result. [NLTK Count method source](https://www.nltk.org/_modules/nltk/text.html#Text.count)"
      ],
      "metadata": {
        "id": "fIM6Ao1Zd4sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ship_count = text1.count('ship') # NLTK's count method from the Text class\n",
        "print(ship_count)\n",
        "all_tokens = text1.tokens\n",
        "print(all_tokens.count('ship')) # Default count method on a list of tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8DBwXHueEYE",
        "outputId": "51b7e2e8-c13d-4ae7-f04a-fbb90a74adae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "507\n",
            "507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Raw Text Source: https://wiki.archlinux.org/title/Arch_Linux"
      ],
      "metadata": {
        "id": "ltO38eqKj5gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "raw_text = \"\"\"Arch Linux is an independently developed, x86-64 general-purpose GNU/Linux distribution that strives to provide the latest stable versions of most software by following a rolling-release model.\n",
        "The default installation is a minimal base system, configured by the user to only add what is purposely required.\n",
        "Arch Linux defines simplicity as without unnecessary additions or modifications. It ships software as released by the original developers (upstream) with minimal distribution-specific (downstream) changes:\n",
        "patches not accepted by upstream are avoided, and Arch's downstream patches consist almost entirely of backported bug fixes that are obsoleted by the project's next release.\n",
        "In a similar fashion, Arch ships the configuration files provided by upstream with changes limited to distribution-specific issues like adjusting the system file paths.\n",
        "It does not add automation features such as enabling a service simply because the package was installed. Packages are only split when compelling advantages exist,\n",
        "such as to save disk space in particularly bad cases of waste. GUI configuration utilities are not officially provided, encouraging users to perform most system configuration from the shell and a text editor.\n",
        "\"\"\"\n",
        "\n",
        "tokens = word_tokenize(raw_text, language='english')\n",
        "print(tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJGai0baj9C2",
        "outputId": "df4ed994-27b3-4f8f-d9d6-6e73d7990031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Arch', 'Linux', 'is', 'an', 'independently', 'developed', ',', 'x86-64', 'general-purpose', 'GNU/Linux']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentences = sent_tokenize(raw_text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKzq3RbMlVXN",
        "outputId": "482d5b32-bf1b-4b34-bc32-44e42871e654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Arch Linux is an independently developed, x86-64 general-purpose GNU/Linux distribution that strives to provide the latest stable versions of most software by following a rolling-release model.', 'The default installation is a minimal base system, configured by the user to only add what is purposely required.', 'Arch Linux defines simplicity as without unnecessary additions or modifications.', \"It ships software as released by the original developers (upstream) with minimal distribution-specific (downstream) changes:\\npatches not accepted by upstream are avoided, and Arch's downstream patches consist almost entirely of backported bug fixes that are obsoleted by the project's next release.\", 'In a similar fashion, Arch ships the configuration files provided by upstream with changes limited to distribution-specific issues like adjusting the system file paths.', 'It does not add automation features such as enabling a service simply because the package was installed.', 'Packages are only split when compelling advantages exist,\\nsuch as to save disk space in particularly bad cases of waste.', 'GUI configuration utilities are not officially provided, encouraging users to perform most system configuration from the shell and a text editor.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(token) for token in tokens]\n",
        "print(stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc_cDp7ymWG3",
        "outputId": "cb175a28-9d98-4542-8017-1157fc72578a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arch', 'linux', 'is', 'an', 'independ', 'develop', ',', 'x86-64', 'general-purpos', 'gnu/linux', 'distribut', 'that', 'strive', 'to', 'provid', 'the', 'latest', 'stabl', 'version', 'of', 'most', 'softwar', 'by', 'follow', 'a', 'rolling-releas', 'model', '.', 'the', 'default', 'instal', 'is', 'a', 'minim', 'base', 'system', ',', 'configur', 'by', 'the', 'user', 'to', 'onli', 'add', 'what', 'is', 'purpos', 'requir', '.', 'arch', 'linux', 'defin', 'simplic', 'as', 'without', 'unnecessari', 'addit', 'or', 'modif', '.', 'it', 'ship', 'softwar', 'as', 'releas', 'by', 'the', 'origin', 'develop', '(', 'upstream', ')', 'with', 'minim', 'distribution-specif', '(', 'downstream', ')', 'chang', ':', 'patch', 'not', 'accept', 'by', 'upstream', 'are', 'avoid', ',', 'and', 'arch', \"'s\", 'downstream', 'patch', 'consist', 'almost', 'entir', 'of', 'backport', 'bug', 'fix', 'that', 'are', 'obsolet', 'by', 'the', 'project', \"'s\", 'next', 'releas', '.', 'in', 'a', 'similar', 'fashion', ',', 'arch', 'ship', 'the', 'configur', 'file', 'provid', 'by', 'upstream', 'with', 'chang', 'limit', 'to', 'distribution-specif', 'issu', 'like', 'adjust', 'the', 'system', 'file', 'path', '.', 'it', 'doe', 'not', 'add', 'autom', 'featur', 'such', 'as', 'enabl', 'a', 'servic', 'simpli', 'becaus', 'the', 'packag', 'wa', 'instal', '.', 'packag', 'are', 'onli', 'split', 'when', 'compel', 'advantag', 'exist', ',', 'such', 'as', 'to', 'save', 'disk', 'space', 'in', 'particularli', 'bad', 'case', 'of', 'wast', '.', 'gui', 'configur', 'util', 'are', 'not', 'offici', 'provid', ',', 'encourag', 'user', 'to', 'perform', 'most', 'system', 'configur', 'from', 'the', 'shell', 'and', 'a', 'text', 'editor', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List at least 5 differences you see in the stems verses the lemmas. You can just write them each on a line\n",
        "  - stem: independ, lemma: independently\n",
        "  - stem: distribut, lemma: distribution\n",
        "  - stem: stabl, lemma: stable\n",
        "  - stem: instal, lemma: installation\n",
        "  - stem: simplic, lemma: simplicity"
      ],
      "metadata": {
        "id": "XfBVUYMpoW5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZzqZgWqnFQJ",
        "outputId": "df089814-6fc2-4694-f8fd-154cb3bc2abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Arch', 'Linux', 'is', 'an', 'independently', 'developed', ',', 'x86-64', 'general-purpose', 'GNU/Linux', 'distribution', 'that', 'strives', 'to', 'provide', 'the', 'latest', 'stable', 'version', 'of', 'most', 'software', 'by', 'following', 'a', 'rolling-release', 'model', '.', 'The', 'default', 'installation', 'is', 'a', 'minimal', 'base', 'system', ',', 'configured', 'by', 'the', 'user', 'to', 'only', 'add', 'what', 'is', 'purposely', 'required', '.', 'Arch', 'Linux', 'defines', 'simplicity', 'a', 'without', 'unnecessary', 'addition', 'or', 'modification', '.', 'It', 'ship', 'software', 'a', 'released', 'by', 'the', 'original', 'developer', '(', 'upstream', ')', 'with', 'minimal', 'distribution-specific', '(', 'downstream', ')', 'change', ':', 'patch', 'not', 'accepted', 'by', 'upstream', 'are', 'avoided', ',', 'and', 'Arch', \"'s\", 'downstream', 'patch', 'consist', 'almost', 'entirely', 'of', 'backported', 'bug', 'fix', 'that', 'are', 'obsoleted', 'by', 'the', 'project', \"'s\", 'next', 'release', '.', 'In', 'a', 'similar', 'fashion', ',', 'Arch', 'ship', 'the', 'configuration', 'file', 'provided', 'by', 'upstream', 'with', 'change', 'limited', 'to', 'distribution-specific', 'issue', 'like', 'adjusting', 'the', 'system', 'file', 'path', '.', 'It', 'doe', 'not', 'add', 'automation', 'feature', 'such', 'a', 'enabling', 'a', 'service', 'simply', 'because', 'the', 'package', 'wa', 'installed', '.', 'Packages', 'are', 'only', 'split', 'when', 'compelling', 'advantage', 'exist', ',', 'such', 'a', 'to', 'save', 'disk', 'space', 'in', 'particularly', 'bad', 'case', 'of', 'waste', '.', 'GUI', 'configuration', 'utility', 'are', 'not', 'officially', 'provided', ',', 'encouraging', 'user', 'to', 'perform', 'most', 'system', 'configuration', 'from', 'the', 'shell', 'and', 'a', 'text', 'editor', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a brief text outlining your opinion of the functionality and the code quality of the NLTK Library:\n",
        "  - NLTK can be quite useful in NLP applications as it provides many analysis functions for huge texts. It also comes with a few prebuilt texts which allows beginners to explore and experiment with these texts.\n",
        "  - I really like that NLTK is an open-source library, and it seems to have exceptional code quality as it allows even beginners to understand what's happening under the hood. The code has well-written comments around it as well that let the viewers get an idea of what's happening even in the complex functions."
      ],
      "metadata": {
        "id": "EuHPSeVyol_l"
      }
    }
  ]
}